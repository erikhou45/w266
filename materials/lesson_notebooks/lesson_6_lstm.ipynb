{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side Notes for Lesson 6\n",
    "\n",
    "Note: not reviewed and/or edited. This is to be seen as a live quick-and-dirty toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model with the Functional API formalism in Keras.\n",
    "\n",
    "This is very useful as it allows us to construct non-sequential models with multiple inputs, multiple outputs, branched models,  etc..\n",
    "\n",
    "Key aspects:\n",
    "\n",
    "* start with definition of inputs\n",
    "* define the model as:\n",
    "$$\\rm next\\_layer\\_activations = layer(layer\\_parameters) (previous\\_layer\\_activations)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    \n",
    "    # inputs - comprised of - for each example in batch:\n",
    "    #             - (four) x_t each of dim 3, \n",
    "    #.            - the initial 2 x 3d state (h and c) \n",
    "    \n",
    "    in_x = tf.keras.layers.Input(shape=(4,3), name=\"in_id\")\n",
    "    in_state_h = tf.keras.layers.Input(shape=(3,), name=\"in_state_h\")\n",
    "    in_state_c = tf.keras.layers.Input(shape=(3,), name=\"in_state_c\")\n",
    "        \n",
    "        \n",
    "    # combine in_state_h and in_state_c into the in_state\n",
    "    in_state = [in_state_h, in_state_c]\n",
    "    \n",
    "    # define a very simple lstem layer, ACTING on the input\n",
    "    \n",
    "    lstm_output = tf.keras.layers.LSTM(3, return_sequences=True, return_state=True,\n",
    "                              kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.1),\n",
    "                              recurrent_initializer=tf.keras.initializers.RandomNormal(stddev=0.1))\\\n",
    "            (in_x, initial_state=in_state)\n",
    "\n",
    "    model = tf.keras.models.Model([in_x, in_state_h, in_state_c], lstm_output)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 14:59:54.957829 4661106112 deprecation.py:506] From /anaconda3/envs/tf1_14/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "in_id (InputLayer)              [(None, 4, 3)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "in_state_h (InputLayer)         [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "in_state_c (InputLayer)         [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 4, 3), (None 84          in_id[0][0]                      \n",
      "                                                                 in_state_h[0][0]                 \n",
      "                                                                 in_state_c[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 84\n",
      "Trainable params: 84\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myModel = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "* is '84' correct?\n",
    "* what would change if we set return_sequences=False?\n",
    "* what would happen if we set return_state=False? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_vector [[[0.18031003 0.52822155 0.17851658]\n",
      "  [0.12420709 0.40717268 0.08703903]\n",
      "  [0.         0.35303497 0.00636824]\n",
      "  [0.         0.31276196 0.        ]]]\n",
      "out_state_h  [[0.         0.31276196 0.        ]]\n",
      "out_state_c  [[1.5253313  1.3554394  0.24917921]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_input = np.array([[[1.1,2,3], [4,5,6], [7,8,9], [10,11,12]]])\n",
    "initial_h = np.array([[1.,2,3]]*1)\n",
    "initial_c = np.array([[1,2,1]]*1)\n",
    "\n",
    "\n",
    "out, state_h, state_c = myModel.predict([lstm_input,initial_h,initial_c],batch_size=4)\n",
    "\n",
    "\n",
    "print('output_vector', out)\n",
    "print('out_state_h ', state_h)\n",
    "print('out_state_c ', state_c)\n",
    "\n",
    "\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "* if we wondered whether we confused out_state_h and out_state_c, how could we tell?\n",
    "* if we change the initial states, do we get different results? (Of course we do, but still good to see.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1_14] *",
   "language": "python",
   "name": "conda-env-tf1_14-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
